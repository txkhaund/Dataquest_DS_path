{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We'll learn another way pandas makes working with data easier. It has many built-in methods and functions for common exploration and analysis tasks.\n",
    "\n",
    "__Dataset__: Fortune Global 500 list [f500.csv]\n",
    "\n",
    "__Source__: https://data.world/chasewillden/fortune-500-companies-2017\n",
    "\n",
    "Here is a data dictionary for some of the columns in the CSV:\n",
    "\n",
    "- ```company```: Name of the company.\n",
    "- ```rank```: Global 500 rank for the company.\n",
    "- ```revenues```: Company's total revenue for the fiscal year, in millions of dollars (USD).\n",
    "- ```revenue_change```: Percentage change in revenue between the current and prior fiscal year.\n",
    "- ```profits```: Net income for the fiscal year, in millions of dollars (USD).\n",
    "- ```ceo```: Company's Chief Executive Officer.\n",
    "- ```industry```: Industry in which the company operates.\n",
    "- ```sector```: Sector in which the company operates.\n",
    "- ```previous_rank```: Global 500 rank for the company for the prior year.\n",
    "- ```country```: Country in which the company is headquartered.\n",
    "- ```hq_location```: City and Country, (or City and State for the USA) where the company is headquarted.\n",
    "- ```employees```: Total employees (full-time equivalent, if available) at fiscal year-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, Walmart to AutoNation\n",
      "Data columns (total 16 columns):\n",
      "rank                        500 non-null int64\n",
      "revenues                    500 non-null int64\n",
      "revenue_change              498 non-null float64\n",
      "profits                     499 non-null float64\n",
      "assets                      500 non-null int64\n",
      "profit_change               436 non-null float64\n",
      "ceo                         500 non-null object\n",
      "industry                    500 non-null object\n",
      "sector                      500 non-null object\n",
      "previous_rank               500 non-null int64\n",
      "country                     500 non-null object\n",
      "hq_location                 500 non-null object\n",
      "website                     500 non-null object\n",
      "years_on_global_500_list    500 non-null int64\n",
      "employees                   500 non-null int64\n",
      "total_stockholder_equity    500 non-null int64\n",
      "dtypes: float64(3), int64(7), object(6)\n",
      "memory usage: 52.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "f500 = pd.read_csv('data/f500.csv', index_col=0)\n",
    "f500_head = f500.head(10)\n",
    "f500.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorized Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with NumPy, we can use any of the standard Python numeric operators with series, including:\n",
    "- ```series_a + series_b``` - Addition\n",
    "- ```series_a - series_b``` - Subtraction\n",
    "- ```series_a * series_b``` - Multiplication (this is unrelated to the multiplications used in linear algebra).\n",
    "- ```series_a / series_b``` - Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_change = f500.loc[:, \"previous_rank\"] - f500.loc[:, \"rank\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Data Exploration Methods\n",
    "\n",
    "Like NumPy, pandas supports many descriptive stats methods that can help us answer these questions. Here are a few of the most useful ones (with links to documentation):\n",
    "- ```Series.max()```\n",
    "- ```Series.min()```\n",
    "- ```Series.mean()```\n",
    "- ```Series.median()```\n",
    "- ```Series.mode()```\n",
    "- ```Series.sum()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_change_max = rank_change.max()\n",
    "rank_change_min = rank_change.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series Describe Method\n",
    "\n",
    "We used the Series.max() and Series.min() methods to figure out the biggest increase and decrease in rank:\n",
    "- Biggest increase in rank: 226\n",
    "- Biggest decrease in rank: -500\n",
    "\n",
    "However, according to the data dictionary, this list should only rank companies on a scale of 1 to 500. Even if the company ranked 1st in the previous year moved to 500th this year, the rank change calculated would be -499. This indicates that there is incorrect data in either the ```rank``` column or ```previous_rank``` column.\n",
    "\n",
    "We'll learn another method that can help us more quickly investigate this issue - the ```Series.describe()``` method. This method tells us how many non-null values are contained in the series, along with the mean, minimum, maximum, and other statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first statistic, __count__, is the same as for numeric columns, showing us the number of non-null values. The other three statistics are new:\n",
    "- ```unique```: Number of unique values in the series.\n",
    "- ```top```: Most common value in the series.\n",
    "- ```freq```: Frequency of the most common value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = f500[\"rank\"]\n",
    "rank_desc = rank.describe()\n",
    "\n",
    "prev_rank = f500[\"previous_rank\"]\n",
    "prev_rank_desc = prev_rank.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    500.000000\n",
       "mean     222.134000\n",
       "std      146.941961\n",
       "min        0.000000\n",
       "25%       92.750000\n",
       "50%      219.500000\n",
       "75%      347.250000\n",
       "max      500.000000\n",
       "Name: previous_rank, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_rank_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Chaining\n",
    "\n",
    "We notice that the minimum rank is 0, which is odd! To investigate the possible cause of this issue, let's confirm the number of 0 values that appear in the previous_rank column.\n",
    "\n",
    "We can skip some of the intermediate code assignments. This is called __method chaining__ — a way to combine multiple methods together in a single line.\n",
    "- When writing code, always assess whether method chaining will make your code harder to read. If it does, it's always preferable to break the code into more than one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of zeros in our previous_rank column\n",
    "zero_previous_rank = f500[\"previous_rank\"].value_counts().loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Exploration Methods\n",
    "\n",
    "We confirmed that 33 companies in the dataframe have a value of 0 in the previous_rank column. Given that multiple companies have a 0 rank, we might conclude that these companies didn't have a rank at all for the previous year. It would make more sense for us to replace these values with a null value instead.\n",
    "\n",
    "Because series and dataframes are two distinct objects, they have their own unique methods. However, there are many times where both series and dataframe objects have a method of the same name that behaves in similar ways. Below are some examples:\n",
    "- ```Series.max()``` and ```DataFrame.max()```\n",
    "- ```Series.min()``` and ```DataFrame.min()```\n",
    "- ```Series.mean()``` and ```DataFrame.mean()```\n",
    "- ```Series.median()``` and ```DataFrame.median()```\n",
    "- ```Series.mode()``` and ```DataFrame.mode()```\n",
    "- ```Series.sum()``` and ```DataFrame.sum()```\n",
    "\n",
    "Unlike their series counterparts, dataframe methods require an _axis parameter_ so we know which axis to calculate across. While you can use integers to refer to the first and second axis, pandas dataframe methods also accept the strings ```\"index\"``` and ```\"columns\"``` for the axis parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rank                            500.0\n",
       "revenues                     485873.0\n",
       "revenue_change                  442.3\n",
       "profits                       45687.0\n",
       "assets                      3473238.0\n",
       "profit_change                  8909.5\n",
       "previous_rank                   500.0\n",
       "years_on_global_500_list         23.0\n",
       "employees                   2300000.0\n",
       "total_stockholder_equity     301893.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the maximum value for only the numeric columns from f500\n",
    "max_f500 = f500.max(numeric_only=True)\n",
    "max_f500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Describe Method\n",
    "\n",
    "Based on the column descriptions, the maximum for each of these columns seems reasonable. Like series objects, dataframe objects also have a ```DataFrame.describe()``` method that we can use to explore the dataframe more quickly.\n",
    "\n",
    "One difference is that we need to manually specify if you want to see the statistics for the non-numeric columns. By default, ```DataFrame.describe()``` will return statistics for only numeric columns. If we wanted to get just the object columns, we need to use the ```include=['O']``` parameter\n",
    "\n",
    "Whereas the ```Series.describe()``` method returns a series object, the ```DataFrame.describe()``` method returns a dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>revenues</th>\n",
       "      <th>revenue_change</th>\n",
       "      <th>profits</th>\n",
       "      <th>assets</th>\n",
       "      <th>profit_change</th>\n",
       "      <th>previous_rank</th>\n",
       "      <th>years_on_global_500_list</th>\n",
       "      <th>employees</th>\n",
       "      <th>total_stockholder_equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>499.000000</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>55416.358000</td>\n",
       "      <td>4.538353</td>\n",
       "      <td>3055.203206</td>\n",
       "      <td>2.436323e+05</td>\n",
       "      <td>24.152752</td>\n",
       "      <td>222.134000</td>\n",
       "      <td>15.036000</td>\n",
       "      <td>1.339983e+05</td>\n",
       "      <td>30628.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>45725.478963</td>\n",
       "      <td>28.549067</td>\n",
       "      <td>5171.981071</td>\n",
       "      <td>4.851937e+05</td>\n",
       "      <td>437.509566</td>\n",
       "      <td>146.941961</td>\n",
       "      <td>7.932752</td>\n",
       "      <td>1.700878e+05</td>\n",
       "      <td>43642.576833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>21609.000000</td>\n",
       "      <td>-67.300000</td>\n",
       "      <td>-13038.000000</td>\n",
       "      <td>3.717000e+03</td>\n",
       "      <td>-793.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.280000e+02</td>\n",
       "      <td>-59909.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.750000</td>\n",
       "      <td>29003.000000</td>\n",
       "      <td>-5.900000</td>\n",
       "      <td>556.950000</td>\n",
       "      <td>3.658850e+04</td>\n",
       "      <td>-22.775000</td>\n",
       "      <td>92.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.293250e+04</td>\n",
       "      <td>7553.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>40236.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1761.600000</td>\n",
       "      <td>7.326150e+04</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>219.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>9.291050e+04</td>\n",
       "      <td>15809.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.250000</td>\n",
       "      <td>63926.750000</td>\n",
       "      <td>6.975000</td>\n",
       "      <td>3954.000000</td>\n",
       "      <td>1.805640e+05</td>\n",
       "      <td>17.700000</td>\n",
       "      <td>347.250000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.689172e+05</td>\n",
       "      <td>37828.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>485873.000000</td>\n",
       "      <td>442.300000</td>\n",
       "      <td>45687.000000</td>\n",
       "      <td>3.473238e+06</td>\n",
       "      <td>8909.500000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>2.300000e+06</td>\n",
       "      <td>301893.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rank       revenues  revenue_change       profits        assets  \\\n",
       "count  500.000000     500.000000      498.000000    499.000000  5.000000e+02   \n",
       "mean   250.500000   55416.358000        4.538353   3055.203206  2.436323e+05   \n",
       "std    144.481833   45725.478963       28.549067   5171.981071  4.851937e+05   \n",
       "min      1.000000   21609.000000      -67.300000 -13038.000000  3.717000e+03   \n",
       "25%    125.750000   29003.000000       -5.900000    556.950000  3.658850e+04   \n",
       "50%    250.500000   40236.000000        0.550000   1761.600000  7.326150e+04   \n",
       "75%    375.250000   63926.750000        6.975000   3954.000000  1.805640e+05   \n",
       "max    500.000000  485873.000000      442.300000  45687.000000  3.473238e+06   \n",
       "\n",
       "       profit_change  previous_rank  years_on_global_500_list     employees  \\\n",
       "count     436.000000     500.000000                500.000000  5.000000e+02   \n",
       "mean       24.152752     222.134000                 15.036000  1.339983e+05   \n",
       "std       437.509566     146.941961                  7.932752  1.700878e+05   \n",
       "min      -793.700000       0.000000                  1.000000  3.280000e+02   \n",
       "25%       -22.775000      92.750000                  7.000000  4.293250e+04   \n",
       "50%        -0.350000     219.500000                 17.000000  9.291050e+04   \n",
       "75%        17.700000     347.250000                 23.000000  1.689172e+05   \n",
       "max      8909.500000     500.000000                 23.000000  2.300000e+06   \n",
       "\n",
       "       total_stockholder_equity  \n",
       "count                500.000000  \n",
       "mean               30628.076000  \n",
       "std                43642.576833  \n",
       "min               -59909.000000  \n",
       "25%                 7553.750000  \n",
       "50%                15809.500000  \n",
       "75%                37828.500000  \n",
       "max               301893.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f500_desc = f500.describe()\n",
    "f500_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment with pandas\n",
    "\n",
    "After reviewing the descriptive statistics for the numeric columns in f500, we can conclude that no values look unusual besides the 0 values in the previous_rank column.\n",
    "\n",
    "We'll learn how to do two things so we can correct these values:\n",
    "- __Perform assignment in pandas.__\n",
    "- Use boolean indexing in pandas.\n",
    "\n",
    "Just like in NumPy, the same techniques that we use to select data could be used for assignment. When we selected a whole column by label and used assignment, we assigned the value to every item in that column.\n",
    "\n",
    "By providing labels for both axes, we can assign them to a single value within our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jim Fitterling'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f500.loc[\"Dow Chemical\",\"ceo\"] = \"Jim Fitterling\"\n",
    "\n",
    "f500.loc[\"Dow Chemical\", \"ceo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Boolean Indexing with pandas Objects\n",
    "\n",
    "While it's helpful to be able to replace specific values when we know the row label ahead of time, this can be cumbersome when we need to replace many values. Instead, we can use __boolean indexing__ to change all rows that meet the same criteria, just like we did with NumPy.\n",
    "\n",
    "Next, let's use boolean indexing to identify companies belonging to the \"Motor Vehicles and Parts\" industry in our Fortune 500 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company\n",
       "Toyota Motor                                 Japan\n",
       "Volkswagen                                 Germany\n",
       "Daimler                                    Germany\n",
       "General Motors                                 USA\n",
       "Ford Motor                                     USA\n",
       "Honda Motor                                  Japan\n",
       "SAIC Motor                                   China\n",
       "Nissan Motor                                 Japan\n",
       "BMW Group                                  Germany\n",
       "Dongfeng Motor                               China\n",
       "Robert Bosch                               Germany\n",
       "Hyundai Motor                          South Korea\n",
       "China FAW Group                              China\n",
       "Beijing Automotive Group                     China\n",
       "Peugeot                                     France\n",
       "Renault                                     France\n",
       "Kia Motors                             South Korea\n",
       "Continental                                Germany\n",
       "Denso                                        Japan\n",
       "Guangzhou Automobile Industry Group          China\n",
       "Tata Motors                                  India\n",
       "ZF Friedrichshafen                         Germany\n",
       "Jardine Matheson                             China\n",
       "Magna International                         Canada\n",
       "Volvo                                       Sweden\n",
       "Hyundai Mobis                          South Korea\n",
       "Aisin Seiki                                  Japan\n",
       "Zhejiang Geely Holding Group                 China\n",
       "Subaru                                       Japan\n",
       "Bridgestone                                  Japan\n",
       "Mazda Motor                                  Japan\n",
       "Suzuki Motor                                 Japan\n",
       "Sumitomo Electric Industries                 Japan\n",
       "Michelin                                    France\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motor_bool = f500[\"industry\"] == \"Motor Vehicles and Parts\"\n",
    "\n",
    "motor_countries = f500.loc[motor_bool, \"country\"] # one specific column\n",
    "\n",
    "motor_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Boolean Arrays to Assign Values\n",
    "\n",
    "We now have all the knowledge we need to fix the 0 values in the previous_rank column:\n",
    "- Perform assignment in pandas.\n",
    "- Use boolean indexing in pandas.\n",
    "\n",
    "We can remove the intermediate step of creating a boolean series, and combine everything into one line. This is the most common way to write pandas code to perform assignment using boolean arrays\n",
    "\n",
    "Now we can follow this pattern to replace the values in the previous_rank column. We'll replace these values with ```np.nan```. Just like in NumPy, ```np.nan``` is used in pandas to represent values that can't be represented numerically, most commonly missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make comparing the values in this column before and after our operation easier, we've added the following line of code:\n",
    "```\n",
    "prev_rank_before = f500[\"previous_rank\"].value_counts(dropna=False).head()\n",
    "```\n",
    "This uses ```Series.value_counts()``` and ```Series.head()``` to display the 5 most common values in the ```previous_rank``` column, but adds an additional ```dropna=False``` parameter, which stops the ```Series.value_counts()``` method from excluding null values when it makes its calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Pandas series for the prev_rank for comparison\n",
    "prev_rank_before = f500[\"previous_rank\"].value_counts(dropna=False).head()\n",
    "\n",
    "# Changing the rank 0 to NAN\n",
    "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
    "# The After series\n",
    "prev_rank_after = f500[\"previous_rank\"].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating New Columns\n",
    "\n",
    "You may have noticed that after we assigned NaN values, the previous_rank column changed dtype.\n",
    "\n",
    "The index of the series that Series.value_counts() produces now shows us floats like 471.0 instead of integers.\n",
    "- Pandas uses the NumPy integer dtype, which does not support NaN values.\n",
    "- Pandas inherits this behavior, and in instances where you try and assign a NaN value to an integer column, pandas will silently convert that column to a float dtype.\n",
    "\n",
    "Now that we've corrected the data, let's create the rank_change series again. This time, we'll add it to our f500 dataframe as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f500[\"rank_change\"] = f500[\"previous_rank\"] - f500[\"rank\"]\n",
    "\n",
    "rank_change_desc = f500[\"rank_change\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Top Performers by Country\n",
    "\n",
    "In this challenge, we'll calculate a specific statistic or attribute of each of the three most common countries from our f500 dataframe.\n",
    "\n",
    "Tasks:\n",
    "- Create a series, industry_usa, containing counts of the two most common values in the industry column for companies headquartered in the USA.\n",
    "- Create a series, sector_china, containing counts of the three most common values in the sector column for companies headquartered in the China.\n",
    "- Create a float object, mean_employees_japan, containing the mean (average) number of employees for companies headquartered in Japan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_countries = f500[\"country\"].value_counts().head(3)\n",
    "\n",
    "# counts of the two most common values in the industry column for companies headquartered in the USA\n",
    "industry_usa = f500.loc[f500[\"country\"] == \"USA\", \"industry\"].value_counts().head(2)\n",
    "\n",
    "# counts of the three most common values in the sector column for companies headquartered in the China.\n",
    "sector_china = f500.loc[f500[\"country\"] == \"China\", \"sector\"].value_counts().head(3)\n",
    "\n",
    "# Not literal Mean ;), if only!\n",
    "# containing the mean (average) number of employees for companies headquartered in Japan.\n",
    "mean_employees_japan = f500.loc[f500[\"country\"] == \"Japan\", \"employees\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "### Fundamentals\n",
    "- How to select data from pandas objects using boolean arrays.\n",
    "- How to assign data using labels and boolean arrays.\n",
    "- How to create new rows and columns in pandas.\n",
    "- Many new methods to make data analysis easier in pandas.\n",
    "\n",
    "Now we will continue with some advance pandas concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring data with pandas: Intermediate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll continue working with the 2017 Fortune Global 500 dataset as we learn more advanced selection and exploration techniques. As a reminder, the data dictionary for the main columns in the f500.csv file is below:\n",
    "- company: Name of the company.\n",
    "- rank: Global 500 rank for the company.\n",
    "- revenues: Company's total revenue for the fiscal year, in millions of dollars (USD).\n",
    "- revenue_change: Percentage change in revenue between the current and prior fiscal year.\n",
    "- profits: Net income for the fiscal year, in millions of dollars (USD).\n",
    "- sector: Sector in which the company operates.\n",
    "- previous_rank: Global 500 rank for the company for the prior year.\n",
    "- country: Country in which the company is headquartered.\n",
    "- hq_location: City and country, (or city and state for the USA) where the company is headquartered.\n",
    "- employees: Total employees (full-time equivalent, if available) at fiscal year-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the data into a pandas dataframe\n",
    "f500 = pd.read_csv('data/f500.csv', index_col=0)\n",
    "f500.index.name = None\n",
    "\n",
    "# Replace the 0 values in the 'previous_rank' column with NaN\n",
    "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
    "\n",
    "f500_selection = f500[[\"rank\", \"revenues\", \"revenue_change\"]].head() # select the top 5 rows from the resp columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV files with pandas\n",
    "```\n",
    "f500 = pd.read_csv(\"f500.csv\", index_col=0)\n",
    "f500.index.name = None\n",
    "```\n",
    "\n",
    "When we compared the files, the index axis labels are actaully the values of the first column in the dataset. ```company```\n",
    "\n",
    "The ```index_col``` parameter is an optional argument and should specify which column to use as the row labels for the dataframe. When we used a value of ```0```, we specified that we wanted to use the first column as the row labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f500 = pd.read_csv('data/f500.csv') # without the index_col parameter\n",
    "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using iloc to select by integer position\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read our CSV file into pandas again. However, this time, we didn't use the ```index_col``` parameter\n",
    "\n",
    "There are two differences with this approach:\n",
    "- The company column is now included as a regular column, instead of being used for the index.\n",
    "- The index labels are now integers starting from 0.\n",
    "\n",
    "In some scenarios, using labels to make selections makes things easier — in others though, it makes things harder.\n",
    "- Just like in NumPy, we can also use integer positions to select data using ```Dataframe.iloc[]``` and ```Series.iloc[]```. It's easy to get ```loc[]``` and ```iloc[]``` confused at first, but the easiest way is to remember the first letter of each method:\n",
    "    - __l__oc: __l__abel based selection\n",
    "    - __i__loc: __integer__ position based selection\n",
    "- Using ```iloc[]``` is almost identical to indexing with NumPy, with integer positions starting at 0 like ndarrays and Python lists.\n",
    "\n",
    "The full syntax for ```DataFrame.iloc[]```, in pseudocode, is:\n",
    "\n",
    "```df.iloc[row_index, column_index]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_row = f500.iloc[4] # 5th row of the f500 dataframe\n",
    "\n",
    "company_value = f500.iloc[0, 0] # selct the first row of the first column 'company'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
